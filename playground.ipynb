{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Conversion Flow Matching - Playground\n",
    "\n",
    "This notebook allows quick experimentation to test the core hypothesis:\n",
    "\n",
    "**Comparing:**\n",
    "1. **Baseline CFM:** Standard Conditional Flow Matching starting from Gaussian Noise\n",
    "2. **SG-Flow:** Rectified Flow starting from Orthogonally Projected Content Subspace\n",
    "\n",
    "**Quick sanity checks:**\n",
    "- Model architecture verification\n",
    "- Loss computation\n",
    "- Small-scale training\n",
    "- Inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Import project modules\n",
    "from config import Config\n",
    "from models.flow_network import FlowNetwork\n",
    "from models.flow_matching import BaselineCFM, SGFlow, create_flow_model\n",
    "from models.decoder import WavLMToMelDecoder\n",
    "from models.system import VoiceConversionSystem\n",
    "from models.projection import OrthogonalProjection\n",
    "\n",
    "config = Config()\n",
    "print(f\"Config loaded: WAVLM_DIM={config.WAVLM_DIM}, BATCH_SIZE={config.BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flow network\n",
    "flow_net = FlowNetwork(\n",
    "    d_input=config.WAVLM_DIM,  # 768\n",
    "    d_model=512,\n",
    "    d_spk=config.d_spk,  # 192\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in flow_net.parameters())\n",
    "print(f\"Flow Network parameters: {num_params:,} ({num_params/1e6:.2f}M)\")\n",
    "\n",
    "# Test forward pass\n",
    "B, T, D = 2, 100, config.WAVLM_DIM\n",
    "x_t = torch.randn(B, T, D).to(device)\n",
    "t = torch.rand(B).to(device)\n",
    "spk = torch.randn(B, config.d_spk).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    v = flow_net(x_t, t, spk)\n",
    "print(f\"Input shape: {x_t.shape}\")\n",
    "print(f\"Output shape: {v.shape}\")\n",
    "print(f\"Output matches input: {v.shape == x_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder (1D ResNet)\n",
    "decoder = WavLMToMelDecoder(\n",
    "    d_wavlm=config.WAVLM_DIM,\n",
    "    d_spk=config.d_spk,\n",
    "    d_hidden=512,\n",
    "    n_mels=config.n_mels,\n",
    "    num_layers=4,\n",
    ").to(device)\n",
    "\n",
    "num_params_dec = sum(p.numel() for p in decoder.parameters())\n",
    "print(f\"Decoder parameters: {num_params_dec:,} ({num_params_dec/1e6:.2f}M)\")\n",
    "\n",
    "# Test decoder forward pass\n",
    "wavlm_feat = torch.randn(B, T, config.WAVLM_DIM).to(device)\n",
    "spk_emb = torch.randn(B, config.d_spk).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mel = decoder(wavlm_feat, spk_emb)\n",
    "print(f\"WavLM input: {wavlm_feat.shape}\")\n",
    "print(f\"Mel output: {mel.shape}\")\n",
    "print(f\"Expected ~{int(T * 1.25)} mel frames (1.25x upsample)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Flow Matching Loss (Baseline CFM vs SG-Flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake projection matrix for testing\n",
    "# In real usage, this comes from SVD on WavLM features\n",
    "D = config.WAVLM_DIM\n",
    "k = config.svd_rank  # 64\n",
    "\n",
    "# Create random orthogonal projection\n",
    "torch.manual_seed(42)\n",
    "random_matrix = torch.randn(D, k)\n",
    "V_k, _ = torch.linalg.qr(random_matrix)\n",
    "P_speaker = V_k @ V_k.T\n",
    "P_content = torch.eye(D) - P_speaker\n",
    "mean = torch.zeros(D)\n",
    "\n",
    "# Save temporary projection matrix\n",
    "os.makedirs(\"temp\", exist_ok=True)\n",
    "torch.save({\n",
    "    \"V_k\": V_k,\n",
    "    \"P_speaker\": P_speaker,\n",
    "    \"P_content\": P_content,\n",
    "    \"mean\": mean,\n",
    "    \"k\": k,\n",
    "}, \"temp/projection_matrix.pt\")\n",
    "print(f\"Created projection matrix: P_content shape = {P_content.shape}\")\n",
    "print(f\"Speaker subspace rank: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both flow models\n",
    "baseline_model = create_flow_model(\n",
    "    method=\"baseline\",\n",
    "    d_input=config.WAVLM_DIM,\n",
    "    d_model=256,  # Smaller for testing\n",
    "    d_spk=config.d_spk,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    ").to(device)\n",
    "\n",
    "sg_flow_model = create_flow_model(\n",
    "    method=\"sg_flow\",\n",
    "    d_input=config.WAVLM_DIM,\n",
    "    d_model=256,\n",
    "    d_spk=config.d_spk,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    projection_path=\"temp/projection_matrix.pt\",\n",
    ").to(device)\n",
    "\n",
    "print(f\"Baseline CFM type: {type(baseline_model).__name__}\")\n",
    "print(f\"SG-Flow type: {type(sg_flow_model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss computation\n",
    "B, T = 4, 50\n",
    "x1 = torch.randn(B, T, config.WAVLM_DIM).to(device)  # Target features\n",
    "spk = torch.randn(B, config.d_spk).to(device)  # Speaker embedding\n",
    "\n",
    "# Compute losses\n",
    "baseline_loss, baseline_info = baseline_model(x1, spk)\n",
    "sg_flow_loss, sg_flow_info = sg_flow_model(x1, spk)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"LOSS COMPARISON (random init, single batch)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Baseline CFM Loss: {baseline_loss.item():.4f}\")\n",
    "print(f\"SG-Flow Loss:      {sg_flow_loss.item():.4f}\")\n",
    "print(f\"\\nBaseline v_pred norm: {baseline_info['v_pred_norm']:.4f}\")\n",
    "print(f\"SG-Flow v_pred norm:  {sg_flow_info['v_pred_norm']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Training Loop (Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_batch(batch_size, seq_len, device):\n",
    "    \"\"\"Create synthetic batch for testing.\"\"\"\n",
    "    return {\n",
    "        \"target_wavlm\": torch.randn(batch_size, seq_len, config.WAVLM_DIM).to(device),\n",
    "        \"target_spk\": torch.randn(batch_size, config.d_spk).to(device),\n",
    "        \"target_mel\": torch.randn(batch_size, int(seq_len * 1.25), config.n_mels).to(device),\n",
    "        \"target_mask\": torch.ones(batch_size, seq_len, dtype=torch.bool).to(device),\n",
    "    }\n",
    "\n",
    "\n",
    "def quick_train(model, optimizer, num_steps=100, batch_size=4, seq_len=50):\n",
    "    \"\"\"Quick training loop for sanity check.\"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    pbar = tqdm(range(num_steps), desc=\"Training\")\n",
    "    for step in pbar:\n",
    "        batch = create_synthetic_batch(batch_size, seq_len, device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.compute_loss(\n",
    "            x1=batch[\"target_wavlm\"],\n",
    "            target_spk=batch[\"target_spk\"],\n",
    "            target_mel=batch[\"target_mel\"],\n",
    "            mask=batch[\"target_mask\"],\n",
    "        )\n",
    "        \n",
    "        loss = outputs[\"loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller models for quick testing\n",
    "def create_small_system(method):\n",
    "    flow = create_flow_model(\n",
    "        method=method,\n",
    "        d_input=config.WAVLM_DIM,\n",
    "        d_model=256,\n",
    "        d_spk=config.d_spk,\n",
    "        num_layers=2,\n",
    "        num_heads=4,\n",
    "        projection_path=\"temp/projection_matrix.pt\" if method == \"sg_flow\" else None,\n",
    "    )\n",
    "    dec = WavLMToMelDecoder(\n",
    "        d_wavlm=config.WAVLM_DIM,\n",
    "        d_spk=config.d_spk,\n",
    "        d_hidden=256,\n",
    "        n_mels=config.n_mels,\n",
    "        num_layers=2,\n",
    "    )\n",
    "    return VoiceConversionSystem(flow, dec).to(device)\n",
    "\n",
    "# Create systems\n",
    "baseline_system = create_small_system(\"baseline\")\n",
    "sg_flow_system = create_small_system(\"sg_flow\")\n",
    "\n",
    "print(f\"Baseline system params: {sum(p.numel() for p in baseline_system.parameters()):,}\")\n",
    "print(f\"SG-Flow system params: {sum(p.numel() for p in sg_flow_system.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both models\n",
    "NUM_STEPS = 200\n",
    "\n",
    "print(\"Training Baseline CFM...\")\n",
    "baseline_opt = optim.AdamW(baseline_system.parameters(), lr=1e-4)\n",
    "baseline_losses = quick_train(baseline_system, baseline_opt, NUM_STEPS)\n",
    "\n",
    "print(\"\\nTraining SG-Flow...\")\n",
    "sg_flow_opt = optim.AdamW(sg_flow_system.parameters(), lr=1e-4)\n",
    "sg_flow_losses = quick_train(sg_flow_system, sg_flow_opt, NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(baseline_losses, label=\"Baseline CFM\", alpha=0.7)\n",
    "plt.plot(sg_flow_losses, label=\"SG-Flow\", alpha=0.7)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss (Synthetic Data)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "window = 20\n",
    "baseline_smooth = np.convolve(baseline_losses, np.ones(window)/window, mode='valid')\n",
    "sg_flow_smooth = np.convolve(sg_flow_losses, np.ones(window)/window, mode='valid')\n",
    "plt.plot(baseline_smooth, label=\"Baseline CFM (smoothed)\", linewidth=2)\n",
    "plt.plot(sg_flow_smooth, label=\"SG-Flow (smoothed)\", linewidth=2)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(f\"Smoothed Loss (window={window})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Baseline Loss: {baseline_losses[-1]:.4f}\")\n",
    "print(f\"Final SG-Flow Loss: {sg_flow_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Inference (ODE Solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_ode_solve(flow_model, x0, spk_embed, num_steps=20):\n",
    "    \"\"\"Simple Euler ODE solver.\"\"\"\n",
    "    device = x0.device\n",
    "    B = x0.shape[0]\n",
    "    dt = 1.0 / num_steps\n",
    "    x_t = x0.clone()\n",
    "    \n",
    "    trajectory = [x_t.clone()]\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        t = torch.full((B,), i / num_steps, device=device)\n",
    "        v = flow_model.velocity_net(x_t, t, spk_embed)\n",
    "        x_t = x_t + v * dt\n",
    "        trajectory.append(x_t.clone())\n",
    "    \n",
    "    return x_t, trajectory\n",
    "\n",
    "\n",
    "# Test inference\n",
    "sg_flow_system.eval()\n",
    "with torch.no_grad():\n",
    "    # Create source features\n",
    "    source = torch.randn(1, 50, config.WAVLM_DIM).to(device)\n",
    "    target_spk = torch.randn(1, config.d_spk).to(device)\n",
    "    \n",
    "    # Get starting point (content projection for SG-Flow)\n",
    "    if hasattr(sg_flow_system.flow_model, 'projection'):\n",
    "        x0 = sg_flow_system.flow_model.projection.project_content(source)\n",
    "    else:\n",
    "        x0 = source.clone()\n",
    "    \n",
    "    # Solve ODE\n",
    "    x1, trajectory = euler_ode_solve(sg_flow_system.flow_model, x0, target_spk, num_steps=20)\n",
    "    \n",
    "    # Decode to mel\n",
    "    mel = sg_flow_system.decoder(x1, target_spk)\n",
    "\n",
    "print(f\"Source shape: {source.shape}\")\n",
    "print(f\"x0 (projected) shape: {x0.shape}\")\n",
    "print(f\"x1 (after ODE) shape: {x1.shape}\")\n",
    "print(f\"Mel output shape: {mel.shape}\")\n",
    "print(f\"Trajectory length: {len(trajectory)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ODE trajectory (first 3 dimensions)\n",
    "trajectory_np = torch.stack(trajectory).cpu().numpy()  # (steps, B, T, D)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot trajectory of first 3 dimensions at middle time step\n",
    "mid_t = trajectory_np.shape[2] // 2\n",
    "for dim in range(3):\n",
    "    plt.subplot(1, 3, dim + 1)\n",
    "    values = trajectory_np[:, 0, mid_t, dim]\n",
    "    plt.plot(values, marker='o', markersize=3)\n",
    "    plt.xlabel(\"ODE Step\")\n",
    "    plt.ylabel(f\"Dim {dim}\")\n",
    "    plt.title(f\"Dimension {dim} trajectory\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f\"ODE Trajectory (t={mid_t}, first 3 dims)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with Real Data (if preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed data exists\n",
    "PREPROCESSED_DIR = \"./preprocessed\"\n",
    "DATA_EXISTS = os.path.exists(os.path.join(PREPROCESSED_DIR, \"metadata.json\"))\n",
    "\n",
    "if DATA_EXISTS:\n",
    "    print(f\"Found preprocessed data at {PREPROCESSED_DIR}\")\n",
    "    from data.dataset import create_dataloader\n",
    "    \n",
    "    train_loader, train_ds = create_dataloader(\n",
    "        PREPROCESSED_DIR, \"train\", batch_size=4, num_workers=0\n",
    "    )\n",
    "    print(f\"Training samples: {len(train_ds)}\")\n",
    "    \n",
    "    # Get one batch\n",
    "    batch = next(iter(train_loader))\n",
    "    print(f\"\\nBatch keys: {batch.keys()}\")\n",
    "    print(f\"target_wavlm shape: {batch['target_wavlm'].shape}\")\n",
    "    print(f\"target_spk shape: {batch['target_spk'].shape}\")\n",
    "    print(f\"target_mel shape: {batch['target_mel'].shape}\")\n",
    "else:\n",
    "    print(f\"No preprocessed data found at {PREPROCESSED_DIR}\")\n",
    "    print(\"\\nTo preprocess LibriTTS dev-clean (~1.2GB, ~40 speakers), run:\")\n",
    "    print(\"  python data/preprocess.py --data_root ./data/LibriTTS/dev-clean --output_dir ./preprocessed\")\n",
    "    print(\"\\nThen compute SVD projection:\")\n",
    "    print(\"  python utils/svd_projection.py --data_dir ./preprocessed --output ./preprocessed/projection_matrix.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training on real data (if available)\n",
    "if DATA_EXISTS:\n",
    "    print(\"Training on real data for 100 steps...\")\n",
    "    \n",
    "    # Check for real projection matrix\n",
    "    real_proj_path = os.path.join(PREPROCESSED_DIR, \"projection_matrix.pt\")\n",
    "    if os.path.exists(real_proj_path):\n",
    "        proj_path = real_proj_path\n",
    "        print(f\"Using real projection matrix: {proj_path}\")\n",
    "    else:\n",
    "        proj_path = \"temp/projection_matrix.pt\"\n",
    "        print(f\"Using synthetic projection matrix: {proj_path}\")\n",
    "    \n",
    "    # Create model with real/synthetic projection\n",
    "    real_system = create_small_system(\"sg_flow\")\n",
    "    real_opt = optim.AdamW(real_system.parameters(), lr=1e-4)\n",
    "    \n",
    "    real_system.train()\n",
    "    real_losses = []\n",
    "    \n",
    "    train_iter = iter(train_loader)\n",
    "    for step in tqdm(range(100), desc=\"Real data training\"):\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:\n",
    "            train_iter = iter(train_loader)\n",
    "            batch = next(train_iter)\n",
    "        \n",
    "        real_opt.zero_grad()\n",
    "        outputs = real_system.compute_loss(\n",
    "            x1=batch[\"target_wavlm\"].to(device),\n",
    "            target_spk=batch[\"target_spk\"].to(device),\n",
    "            target_mel=batch[\"target_mel\"].to(device),\n",
    "            mask=batch[\"target_mask\"].to(device),\n",
    "        )\n",
    "        outputs[\"loss\"].backward()\n",
    "        real_opt.step()\n",
    "        real_losses.append(outputs[\"loss\"].item())\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(real_losses)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training on Real Data\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping real data training (no preprocessed data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import shutil\n",
    "if os.path.exists(\"temp\"):\n",
    "    shutil.rmtree(\"temp\")\n",
    "    print(\"Cleaned up temp directory\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PLAYGROUND COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps (using LibriTTS dev-clean, ~1.2GB, ~40 speakers):\")\n",
    "print(\"\")\n",
    "print(\"1. Setup environment:\")\n",
    "print(\"   ./setup.sh\")\n",
    "print(\"\")\n",
    "print(\"2. Preprocess data:\")\n",
    "print(\"   python data/preprocess.py --data_root ./data/LibriTTS/dev-clean --output_dir ./preprocessed\")\n",
    "print(\"\")\n",
    "print(\"3. Compute SVD projection:\")\n",
    "print(\"   python utils/svd_projection.py --data_dir ./preprocessed --output ./preprocessed/projection_matrix.pt\")\n",
    "print(\"\")\n",
    "print(\"4. Train and compare:\")\n",
    "print(\"   python train.py --mode baseline --data_dir ./preprocessed  # Baseline CFM\")\n",
    "print(\"   python train.py --mode sg_flow --data_dir ./preprocessed   # SG-Flow (your method)\")\n",
    "print(\"\")\n",
    "print(\"5. Inference:\")\n",
    "print(\"   python inference.py --checkpoint checkpoints/sg_flow_best.pt --source_wav ... --ref_wav ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
